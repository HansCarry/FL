{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, random, copy, os, glob, time\n",
    "from itertools import chain, combinations, permutations\n",
    "from pprint import pprint\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision as tv\n",
    "from torchvision import datasets, transforms as T\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from utils.parameters import args_parser\n",
    "from utils.data_process import prepareIID, prepareNIID1, prepareNIID2, prepareNIID12\n",
    "from models.Nets import SmallMLP_MNIST, MediumMLP_MNIST, LargeMLP_MNIST, SmallMLP_EMNIST, MediumMLP_EMNIST, LargeMLP_EMNIST\n",
    "from utils.save_file import createDirectory, deleteAllModels, saveCheckpoint, print_parameters, loadCheckpoint\n",
    "from models.Fed import FedAvg\n",
    "from utils.helpers import powerset, grangerset, aggListOfDicts, getAllClients\n",
    "\n",
    "from models.server import server\n",
    "from models.clients import initClients\n",
    "\n",
    "#新加的\n",
    "from PIL import ImageFile\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get cpu or gpu device for training 选择cpu或者gpu\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"  \n",
    "# Create subdirectories 创建存放模型的子目录\n",
    "model_path = './models'\n",
    "# Initialize system and define helper functions 初始化系统并定义助手功能\n",
    "createDirectory(model_path)\n",
    "# Delete existing .pt files from previous run 从上次运行中删除现有.pt文件\n",
    "deleteAllModels(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#训练集与测试集\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True # To prevent error during loading broken images\n",
    "PATH_TRAIN = \"train\"\n",
    "PATH_TEST  = \"test\"\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "TOTAL_SIZE = len(os.listdir(PATH_TRAIN + \"/Normal\")) + len(\n",
    "os.listdir(PATH_TRAIN + \"/Infected\"))\n",
    "TOTAL_TEST_SIZE = len(os.listdir(PATH_TEST + \"/Normal\")) + len(\n",
    "os.listdir(PATH_TEST + \"/Infected\"))\n",
    "STEPS_PER_EPOCH = TOTAL_SIZE // BATCH_SIZE\n",
    "STEPS_PER_TEST_EPOCH = TOTAL_TEST_SIZE // BATCH_SIZE\n",
    "\n",
    "IMAGE_H, IMAGE_W = 224, 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = torchvision.transforms.Compose(\n",
    "[  # Applying Augmentation\n",
    "    torchvision.transforms.Resize((IMAGE_H, IMAGE_W)),\n",
    "    torchvision.transforms.RandomHorizontalFlip(p=0.5),\n",
    "    torchvision.transforms.RandomVerticalFlip(p=0.5),\n",
    "    torchvision.transforms.RandomRotation(30),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",
    "        ),\n",
    "])  # Normalizing data\n",
    "    \n",
    "train_data = torchvision.datasets.ImageFolder(root=PATH_TRAIN, transform=transform)\n",
    "test_data = torchvision.datasets.ImageFolder(root=PATH_TEST, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_OF_CLIENTS = 5\n",
    "train_datasets = prepareIID(train_data, NUM_OF_CLIENTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloaders = [DataLoader(train_dataset, batch_size=BATCH_SIZE) for train_dataset in train_datasets]\n",
    "test_dataloader = DataLoader(test_data, batch_size=BATCH_SIZE * 2) #batch_size批次大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define network model architecture 定义网络模型体系结构\n",
    "FederatedModel = None #联邦学习网络模型\n",
    "FederatedModel = torchvision.models.resnet18(False)\n",
    "feature = FederatedModel.fc.in_features\n",
    "FederatedModel.fc = nn.Linear(feature, 2)\n",
    "FederatedModel.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "FederatedLossFunc = nn.CrossEntropyLoss() #损失函数\n",
    "FederatedOptimizer = torch.optim.AdamW(FederatedModel.parameters(), lr=1e-4)\n",
    "FederatedLearnRate = 0.0001 #学习率\n",
    "FederatedMomentum = 0.9 #动量\n",
    "FederatedWeightDecay = 1e-5 #权重衰退"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "server = server(FederatedModel, FederatedLossFunc, FederatedOptimizer, FederatedLearnRate, FederatedMomentum,FederatedWeightDecay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing server model...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'AdamW' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/root/autodl-nas/FedML-pytorch-master/run_Fed.ipynb 单元格 10\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bregion-41.seetacloud.com/root/autodl-nas/FedML-pytorch-master/run_Fed.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m server \u001b[39m=\u001b[39m server\u001b[39m.\u001b[39;49minitServer(model_path, \u001b[39m'\u001b[39;49m\u001b[39mFedAvg\u001b[39;49m\u001b[39m'\u001b[39;49m, test_dataloader)\n",
      "File \u001b[0;32m~/autodl-nas/FedML-pytorch-master/models/server.py:29\u001b[0m, in \u001b[0;36mserver.initServer\u001b[0;34m(self, model_path, folder_name, dataloader)\u001b[0m\n\u001b[1;32m     27\u001b[0m server_model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mFederatedModel\n\u001b[1;32m     28\u001b[0m server_loss_func \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mFederatedLossFunc\n\u001b[0;32m---> 29\u001b[0m server_optimizer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mFederatedOptimizer(server_model\u001b[39m.\u001b[39;49mparameters(), lr\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mFederatedLearnRate,\n\u001b[1;32m     30\u001b[0m                                       momentum\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mFederatedMomentum, weight_decay\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mFederatedWeightDecay)\n\u001b[1;32m     31\u001b[0m server_dataloader \u001b[39m=\u001b[39m dataloader\n\u001b[1;32m     33\u001b[0m \u001b[39mprint\u001b[39m(server_model, \u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'AdamW' object is not callable"
     ]
    }
   ],
   "source": [
    "server = server.initServer(model_path, 'FedAvg', test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing clients...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'server' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/root/autodl-nas/FedML-pytorch-master/run_Fed.ipynb 单元格 11\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bregion-41.seetacloud.com/root/autodl-nas/FedML-pytorch-master/run_Fed.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m clients \u001b[39m=\u001b[39m initClients(\u001b[39m4\u001b[39;49m, \u001b[39m0\u001b[39;49m, \u001b[39m1\u001b[39;49m, server,train_dataloaders)\n",
      "File \u001b[0;32m~/autodl-nas/FedML-pytorch-master/models/clients.py:26\u001b[0m, in \u001b[0;36minitClients\u001b[0;34m(num_norm, num_free, num_avsl, server, dataloaders)\u001b[0m\n\u001b[1;32m     20\u001b[0m     client_name \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mclient_\u001b[39m\u001b[39m{\u001b[39;00mn\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[1;32m     22\u001b[0m     \u001b[39m# Collect client's objects into a reference dictionary 将客户端的对象收集到参考字典中\u001b[39;00m\n\u001b[1;32m     23\u001b[0m     clients \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m [{\n\u001b[1;32m     24\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mname\u001b[39m\u001b[39m'\u001b[39m: client_name,\n\u001b[1;32m     25\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mbehaviour\u001b[39m\u001b[39m'\u001b[39m: behaviour,\n\u001b[0;32m---> 26\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mfilepath\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mserver[\u001b[39m\"\u001b[39m\u001b[39mclient_filepath\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mclient_name\u001b[39m}\u001b[39;00m\u001b[39m.pt\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     27\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mdataloader\u001b[39m\u001b[39m'\u001b[39m: dataloaders[n]\n\u001b[1;32m     28\u001b[0m     }]\n\u001b[1;32m     30\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mClient Name / Behaviour:\u001b[39m\u001b[39m'\u001b[39m, [(client[\u001b[39m'\u001b[39m\u001b[39mname\u001b[39m\u001b[39m'\u001b[39m], client[\u001b[39m'\u001b[39m\u001b[39mbehaviour\u001b[39m\u001b[39m'\u001b[39m]) \u001b[39mfor\u001b[39;00m client \u001b[39min\u001b[39;00m clients], \u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m     32\u001b[0m \u001b[39mreturn\u001b[39;00m clients\n",
      "\u001b[0;31mTypeError\u001b[0m: 'server' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "clients = initClients(4, 0, 1, server,train_dataloaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
